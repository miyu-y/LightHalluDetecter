{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../dataset/rag_truth_train.json\", \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "with open(\"../dataset/rag_truth_dev.json\", \"r\") as f:\n",
    "    dev_data = json.load(f)\n",
    "with open(\"../dataset/rag_truth_test.json\", \"r\") as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(data):\n",
    "    for d in data:\n",
    "        d[\"text\"] = \"Please judge the following statement whether it includes hallucination or not based on the Document above: \" + d[\"text\"]\n",
    "    return data\n",
    "\n",
    "train_data = add_prefix(train_data)\n",
    "dev_data = add_prefix(dev_data)\n",
    "test_data = add_prefix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type: QA, Data2txt, Summary\n",
    "task_name = \"Data2txt\"\n",
    "train_data = [d for d in train_data if d[\"task_type\"] == task_name]\n",
    "dev_data = [d for d in dev_data if d[\"task_type\"] == task_name]\n",
    "test_data = [d for d in test_data if d[\"task_type\"] == task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def create_trip(data, id_list):\n",
    "    trip = []\n",
    "    for id in id_list:\n",
    "        num = 0\n",
    "        no_hal = []\n",
    "        has_hal = []\n",
    "        for d in data:\n",
    "            if d[\"source_id\"] == id:\n",
    "                num += 1\n",
    "                ref = d[\"ref\"]\n",
    "                if d[\"labels\"] == 0:\n",
    "                    no_hal.append(d[\"text\"])\n",
    "                else:\n",
    "                    has_hal.append(d[\"text\"])\n",
    "            if num == 6:\n",
    "                num = 0\n",
    "                if no_hal == [] or has_hal == []:\n",
    "                    break\n",
    "                random.seed(id)\n",
    "                no_hal = random.sample(no_hal, len(no_hal))\n",
    "                has_hal = random.sample(has_hal, len(has_hal))\n",
    "\n",
    "                if len(no_hal) == 1:\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": no_hal[0], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": has_hal[0], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[1], \"text\": has_hal[1], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[2], \"text\": has_hal[2], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[3], \"text\": has_hal[3], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[4], \"text\": has_hal[4], \"labels\": 1}\n",
    "                    )\n",
    "                elif len(no_hal) == 2:\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": no_hal[0], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": has_hal[0], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": no_hal[1], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": has_hal[1], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[2], \"text\": has_hal[2], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[3], \"text\": has_hal[3], \"labels\": 1}\n",
    "                    )\n",
    "                elif len(no_hal) == 3:\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": no_hal[0], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": has_hal[0], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": no_hal[1], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": has_hal[1], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[2], \"negative\": has_hal[2], \"text\": no_hal[2], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[2], \"negative\": has_hal[2], \"text\": has_hal[2], \"labels\": 1}\n",
    "                    )\n",
    "                elif len(no_hal) == 4:\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": no_hal[0], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": has_hal[0], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": no_hal[1], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[1], \"text\": has_hal[1], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[2], \"negative\": has_hal[0], \"text\": no_hal[2], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[3], \"negative\": has_hal[1], \"text\": no_hal[3], \"labels\": 0}\n",
    "                    )\n",
    "                elif len(no_hal) == 5:\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": no_hal[0], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[0], \"negative\": has_hal[0], \"text\": has_hal[0], \"labels\": 1}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[1], \"negative\": has_hal[0], \"text\": no_hal[1], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[2], \"negative\": has_hal[0], \"text\": no_hal[2], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[3], \"negative\": has_hal[0], \"text\": no_hal[3], \"labels\": 0}\n",
    "                    )\n",
    "                    trip.append(\n",
    "                        {\"anchor\": ref, \"positive\": no_hal[4], \"negative\": has_hal[0], \"text\": no_hal[4], \"labels\": 0}\n",
    "                    )\n",
    "\n",
    "                no_hal = []\n",
    "                has_hal = []\n",
    "                break\n",
    "\n",
    "    return trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305 210 368\n"
     ]
    }
   ],
   "source": [
    "train_id = [d[\"source_id\"] for d in train_data]\n",
    "train_id = list(set(train_id))\n",
    "dev_id = [d[\"source_id\"] for d in dev_data]\n",
    "dev_id = list(set(dev_id))\n",
    "test_id = [d[\"source_id\"] for d in test_data]\n",
    "test_id = list(set(test_id))\n",
    "print(len(train_id), len(dev_id), len(test_id))\n",
    "train_trip = create_trip(train_data, train_id)\n",
    "dev_trip = create_trip(dev_data, dev_id)\n",
    "test_trip = create_trip(test_data, test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12336, 1116, 2208)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_trip), len(dev_trip), len(test_trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gs/fs/tga-kprogram-arase/yamada/.acl2025/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'text', 'labels'],\n",
       "        num_rows: 12336\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'text', 'labels'],\n",
       "        num_rows: 1116\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['anchor', 'positive', 'negative', 'text', 'labels'],\n",
       "        num_rows: 2208\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.DataFrame(train_trip)\n",
    "dev_df = pd.DataFrame(dev_trip)\n",
    "test_df = pd.DataFrame(test_trip)\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "dev_ds = Dataset.from_pandas(dev_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "tri_raw_datasets = DatasetDict({\"train\": train_ds, \"dev\": dev_ds, \"test\": test_ds})\n",
    "tri_raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "tri_tokenizer.padding_side = \"right\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': '{\\'question\\': \\'how bad canceling a credit card affect your score\\', \\'passages\\': \"passage 1:You want to cancel your credit card. Before you pick up your scissors, know this: Canceling a credit card the right way involves more than simply snipping it in two. It requires you to follow specific steps to close the credit card account for good with the least damage to your credit score.easons to cancel a credit card The decision to cancel a credit card may be based on the desire to avoid excessive spending or if the terms of the card (such as annual fees or a high interest rate) are no longer friendly.\\\\n\\\\npassage 2:This will have a tremendous impact on your score. The amounts that you owe will also play an important factor in the determination of your FICO score and should be considered. Canceling credit cards will not adversely affect your score much.It will impact your credit score but the potential result is negligible, and therefore it is not worth paying annual fees or dues simply to maintain an open line of credit. Maintaining a card that has no activity is essentially pointless.his will have a tremendous impact on your score. The amounts that you owe will also play an important factor in the determination of your FICO score and should be considered. Canceling credit cards will not adversely affect your score much.\\\\n\\\\npassage 3:To make sure closing one card doesn\\'t impact your score, pay off balances on all other cards. If you have zero balances, your credit utilization rate is zero, and won\\'t be impacted by the loss of a balance. However, experts say this step may be unnecessary for most people.easons to cancel a credit card The decision to cancel a credit card may be based on the desire to avoid excessive spending or if the terms of the card (such as annual fees or a high interest rate) are no longer friendly.\\\\n\\\\n\"}',\n",
       " 'positive': \"Please judge the following statement whether it includes hallucination or not based on the Document above: Based on the given passages, here is the answer to the question:\\n\\nCanceling a credit card can have a minor negative impact on your credit score, but the impact is not significant enough to warrant paying annual fees or keeping an inactive card. According to passage 2, canceling credit cards will not adversely affect your score much, and paying off balances on all other cards before canceling one can help minimize any potential impact on your credit utilization rate. However, the decision to cancel a credit card should not solely be based on its potential effect on your credit score. Instead, it should be based on factors such as the card's terms, your financial situation, and your ability to manage multiple cards responsibly.\",\n",
       " 'negative': 'Please judge the following statement whether it includes hallucination or not based on the Document above: Based on the given passages, canceling a credit card does not have a significant impact on your credit score. The potential result is negligible, and therefore it is not worth paying annual fees or dues simply to maintain an open line of credit. Experts suggest paying off balances on all other cards before closing one card to ensure that your credit score is not impacted negatively.',\n",
       " 'text': \"Please judge the following statement whether it includes hallucination or not based on the Document above: Based on the given passages, here is the answer to the question:\\n\\nCanceling a credit card can have a minor negative impact on your credit score, but the impact is not significant enough to warrant paying annual fees or keeping an inactive card. According to passage 2, canceling credit cards will not adversely affect your score much, and paying off balances on all other cards before canceling one can help minimize any potential impact on your credit utilization rate. However, the decision to cancel a credit card should not solely be based on its potential effect on your credit score. Instead, it should be based on factors such as the card's terms, your financial situation, and your ability to manage multiple cards responsibly.\",\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True,max_length=512)\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True,max_length=512)\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True,max_length=512)\n",
    "    #text = tri_tokenizer(examples[\"text\"], truncation=True,max_length=512, padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "        #\"text_input_ids\": text[\"input_ids\"],\n",
    "        #\"text_attention_mask\": text[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\", \"text\"])\n",
    "#tri_tokenized_datasets.set_format(\"torch\")\n",
    "tri_data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "class CustomDataCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        # features: [{'anchor_input_ids': ..., 'anchor_attention_mask': ..., ...}, ...]\n",
    "        \n",
    "        anchor_ids = [torch.tensor(x['anchor_input_ids']).clone().detach() for x in features]\n",
    "        positive_ids = [torch.tensor(x['positive_input_ids']).clone().detach() for x in features]\n",
    "        negative_ids = [torch.tensor(x['negative_input_ids']).clone().detach() for x in features]\n",
    "        #text_ids = [torch.tensor(x['text_input_ids']).clone().detach() for x in features]\n",
    "        \n",
    "        anchor_mask = [torch.tensor(x['anchor_attention_mask']).clone().detach() for x in features]\n",
    "        positive_mask = [torch.tensor(x['positive_attention_mask']).clone().detach() for x in features]\n",
    "        negative_mask = [torch.tensor(x['negative_attention_mask']).clone().detach() for x in features]\n",
    "        #text_mask = [torch.tensor(x['text_attention_mask']).clone().detach() for x in features]\n",
    "\n",
    "        anchor_ids = pad_sequence(anchor_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        positive_ids = pad_sequence(positive_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        negative_ids = pad_sequence(negative_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        #text_ids = pad_sequence(text_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        anchor_mask = pad_sequence(anchor_mask, batch_first=True, padding_value=0)\n",
    "        positive_mask = pad_sequence(positive_mask, batch_first=True, padding_value=0)\n",
    "        negative_mask = pad_sequence(negative_mask, batch_first=True, padding_value=0)\n",
    "        #text_mask = pad_sequence(text_mask, batch_first=True, padding_value=0)\n",
    "\n",
    "        labels = torch.tensor([x['labels'] for x in features])\n",
    "        \n",
    "        batch = {\n",
    "            \"input_ids\": [anchor_ids, positive_ids, negative_ids],#, text_ids],\n",
    "            \"attention_mask\": [anchor_mask, positive_mask, negative_mask],#, text_mask],\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "        return batch\n",
    "\n",
    "\n",
    "tri_data_collator = CustomDataCollator(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base_model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, text_logits, labels):\n",
    "    text_targets = torch.tensor(labels).clone().detach().to(device)\n",
    "    classification_loss = nn.CrossEntropyLoss()(text_logits, text_targets)\n",
    "\n",
    "    triplet_loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "        margin=0.5, distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)\n",
    "    )\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1).tolist()\n",
    "\n",
    "    labels = labels.tolist()\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"recall\": recall, \"precision\": precision, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from models.models_phi import TripletModel\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",  \n",
    "    save_steps=10000,\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    fp16 = True,\n",
    "    gradient_accumulation_steps=12,\n",
    "    logging_dir=\"./logs\",\n",
    "    remove_unused_columns=False,\n",
    "    report_to=[],\n",
    "    optim=\"adafactor\",\n",
    ")\n",
    "\n",
    "tri_model = TripletModel(base_model, triplet_loss)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tri_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tri_tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tri_tokenized_datasets[\"dev\"],\n",
    "    data_collator=tri_data_collator,\n",
    "    tokenizer=tri_tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=tri_tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "import os\n",
    "\n",
    "name = \"../trained_model/triplet_phi\"\n",
    "trainer.save_model(name)\n",
    "trainer.save_state()\n",
    "tri_model.save_pretrained(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you restart kernel, you need to load the model and tokenizer again.\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding\n",
    "import torch\n",
    "from models.models_phi import TripletModel\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, text_logits, labels):\n",
    "    text_targets = torch.tensor(labels).clone().detach().to(device)\n",
    "    classification_loss = nn.CrossEntropyLoss()(text_logits, text_targets)\n",
    "\n",
    "    triplet_loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "        margin=0.5, distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)\n",
    "    )\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "    return classification_loss, triplet_loss\n",
    "\n",
    "\n",
    "base_model = AutoModel.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "# load model and tokenizer\n",
    "name = \"../trained_models/triplet_phi\"\n",
    "tri_model = TripletModel.from_pretrained(base_model, triplet_loss, name)\n",
    "tri_tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tri_model.to(device)\n",
    "\n",
    "\n",
    "def tri_tokenize_function(examples):\n",
    "    anchor = tri_tokenizer(examples[\"anchor\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    positive = tri_tokenizer(examples[\"positive\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    negative = tri_tokenizer(examples[\"negative\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "    #text = tri_tokenizer(examples[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"anchor_input_ids\": anchor[\"input_ids\"],\n",
    "        \"anchor_attention_mask\": anchor[\"attention_mask\"],\n",
    "        \"positive_input_ids\": positive[\"input_ids\"],\n",
    "        \"positive_attention_mask\": positive[\"attention_mask\"],\n",
    "        \"negative_input_ids\": negative[\"input_ids\"],\n",
    "        \"negative_attention_mask\": negative[\"attention_mask\"],\n",
    "        #\"text_input_ids\": text[\"input_ids\"],\n",
    "        #\"text_attention_mask\": text[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "\n",
    "tri_tokenized_datasets = tri_raw_datasets.map(tri_tokenize_function, batched=True)\n",
    "tri_tokenized_datasets = tri_tokenized_datasets.remove_columns([\"anchor\", \"positive\", \"negative\", \"text\"])\n",
    "# tokenized_datasets.set_format(\"torch\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tri_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"../results_test.json\"):\n",
    "    with open(\"../results_test.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "else:\n",
    "    data = []\n",
    "    for i, d in enumerate(test_data):\n",
    "        data.append({\"id\": i, \"label\": d[\"labels\"], \"task\": d[\"task_type\"]})\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "tri_model.eval()\n",
    "\n",
    "\n",
    "for i,d in tqdm(enumerate(tri_tokenized_datasets[\"test\"])):\n",
    "    anchor_input_ids = torch.tensor(d[\"anchor_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    positive_input_ids = torch.tensor(d[\"positive_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    negative_input_ids = torch.tensor(d[\"negative_input_ids\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    input_ids = [anchor_input_ids, positive_input_ids, negative_input_ids]\n",
    "    \n",
    "    anchor_attention_mask = torch.tensor(d[\"anchor_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    positive_attention_mask = torch.tensor(d[\"positive_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    negative_attention_mask = torch.tensor(d[\"negative_attention_mask\"], dtype=torch.long).unsqueeze(0).to(device)\n",
    "    attention_mask = [anchor_attention_mask, positive_attention_mask, negative_attention_mask]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = tri_model(input_ids=input_ids, attention_mask=attention_mask, labels=[d[\"labels\"]])\n",
    "        logits = outputs.logits\n",
    "        predicted_index = torch.argmax(logits, dim=-1)\n",
    "    data[i][\"triplet_phi_logits\"] = logits.cpu().numpy().tolist()[0]\n",
    "    data[i][\"triplet_phi_label\"] = predicted_index.cpu().numpy().tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "true_labels = [item['label'] for item in data]\n",
    "predicted_labels = [item['triplet_phi_label'] for item in data]\n",
    "\n",
    "count = Counter(predicted_labels)\n",
    "print(count)\n",
    "\n",
    "accuracy_score(true_labels, predicted_labels), f1_score(true_labels, predicted_labels), precision_score(true_labels, predicted_labels), recall_score(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results_test.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".acl2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69411aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"results_test.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5179a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/rag_truth_span.json\", \"r\") as f:\n",
    "    test_data_span = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b37abcc",
   "metadata": {},
   "source": [
    "### Preparation for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25463580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add token count\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "for i in range(len(results)):\n",
    "    d = test_data_span[i]\n",
    "    hal_tok = 0\n",
    "    if d[\"labels\"] == 1:\n",
    "        for h in d[\"hallucination_id\"]:\n",
    "            hal_tok += len(tokenizer(h[\"text\"], truncation=True, max_length=512)[\"input_ids\"])\n",
    "    results[i][\"hal_token\"] = hal_tok\n",
    "    results[i][\"all_token\"] = len(tokenizer(d[\"text\"], truncation=True, max_length=512)[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If filter with specific task\n",
    "results_new = []\n",
    "test_data_span_new = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    if results[i][\"task\"] == \"Summary\":\n",
    "        results_new.append(results[i])\n",
    "        test_data_span_new.append(test_data_span[i])\n",
    "results = results_new\n",
    "test_data_span = test_data_span_new\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_abc : a: before_predict, b: after_predict, c: label\n",
    "id_000 = []\n",
    "id_001 = []\n",
    "id_010 = []\n",
    "id_011 = []\n",
    "id_100 = []\n",
    "id_101 = []\n",
    "id_110 = []\n",
    "id_111 = []\n",
    "\n",
    "before = \"gpt4o\"\n",
    "after = \"triplet_rob_label\"\n",
    "for i, result in enumerate(results):\n",
    "    if result[before] == 0 and result[after] == 0 and result[\"label\"] == 0:\n",
    "        id_000.append(i)\n",
    "    elif result[before] == 0 and result[after] == 0 and result[\"label\"] == 1:\n",
    "        id_001.append(i)\n",
    "    elif result[before] == 0 and result[after] == 1 and result[\"label\"] == 0:\n",
    "        id_010.append(i)\n",
    "    elif result[before] == 0 and result[after] == 1 and result[\"label\"] == 1:\n",
    "        id_011.append(i)\n",
    "    elif result[before] == 1 and result[after] == 0 and result[\"label\"] == 0:\n",
    "        id_100.append(i)\n",
    "    elif result[before] == 1 and result[after] == 0 and result[\"label\"] == 1:\n",
    "        id_101.append(i)\n",
    "    elif result[before] == 1 and result[after] == 1 and result[\"label\"] == 0:\n",
    "        id_110.append(i)\n",
    "    elif result[before] == 1 and result[after] == 1 and result[\"label\"] == 1:\n",
    "        id_111.append(i)\n",
    "\n",
    "\n",
    "print(len(id_000), len(id_001), len(id_010), len(id_011), len(id_100), len(id_101), len(id_110), len(id_111))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8397f9c",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "true_labels = [item[\"label\"] for item in results]\n",
    "predicted_labels = [item[\"triplet_rob_label\"] for item in results]\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=\"binary\") \n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ba64b",
   "metadata": {},
   "source": [
    "### Effect of Hallucinating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hallucinated cases in each model\n",
    "hal_model_qa = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "hal_model_d2t = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "hal_model_sum = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "\n",
    "for d in test_data_span:\n",
    "    if d[\"hallucination_id\"] == []:\n",
    "        continue\n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        hal_model_qa[d[\"model\"]] += 1\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        hal_model_d2t[d[\"model\"]] += 1\n",
    "    else:\n",
    "        hal_model_sum[d[\"model\"]] += 1\n",
    "print(hal_model_qa)\n",
    "print(hal_model_d2t)\n",
    "print(hal_model_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hallucinated cases detected by after_method\n",
    "hal_model_qa_imp = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "hal_model_d2t_imp = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "hal_model_sum_imp = {\n",
    "    \"gpt-3.5-turbo-0613\": 0,\n",
    "    \"gpt-4-0613\": 0,\n",
    "    \"llama-2-7b-chat\": 0,\n",
    "    \"llama-2-13b-chat\": 0,\n",
    "    \"llama-2-70b-chat\": 0,\n",
    "    \"mistral-7B-instruct\": 0,\n",
    "}\n",
    "\n",
    "for i in id_011 + id_111:\n",
    "    d = test_data_span[i]\n",
    "    if d[\"hallucination_id\"] == []:\n",
    "        continue\n",
    "\n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        hal_model_qa_imp[d[\"model\"]] += 1\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        hal_model_d2t_imp[d[\"model\"]] += 1\n",
    "    else:\n",
    "        hal_model_sum_imp[d[\"model\"]] += 1\n",
    "\n",
    "print(hal_model_qa_imp)\n",
    "print(hal_model_d2t_imp)\n",
    "print(hal_model_sum_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_metrics_model(predictions, labels, models, task=None, task_type=None):\n",
    "    models_list = [\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"llama-2-7b-chat\",\n",
    "        \"llama-2-13b-chat\",\n",
    "        \"llama-2-70b-chat\",\n",
    "        \"mistral-7B-instruct\",\n",
    "    ]\n",
    "    f1_s = []\n",
    "    for model in models_list:\n",
    "        p_sub = []\n",
    "        l_sub = []\n",
    "        for i in range(len(predictions)):\n",
    "            if models[i] == model:\n",
    "                if task and task_type[i] != task:\n",
    "                    continue\n",
    "                p_sub.append(predictions[i])\n",
    "                l_sub.append(labels[i])\n",
    "        f1_s.append(f1_score(l_sub, p_sub, average=\"binary\"))\n",
    "\n",
    "    return f1_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae2c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [r[\"label\"] for r in results]\n",
    "before_labels = [r[\"gpt4o\"] for r in results]\n",
    "after_labels = [r[\"triplet_rob_label\"] for r in results]\n",
    "models = [t[\"model\"] for t in test_data_span]\n",
    "tasks = [r[\"task\"] for r in results]\n",
    "\n",
    "print(compute_metrics_model(before_labels, true_labels, models))\n",
    "print(compute_metrics_model(after_labels, true_labels, models))\n",
    "print(\"QA\")\n",
    "print(compute_metrics_model(before_labels, true_labels, models, \"QA\", tasks))\n",
    "print(compute_metrics_model(after_labels, true_labels, models, \"QA\", tasks))\n",
    "print(\"Data2txt\")\n",
    "print(compute_metrics_model(before_labels, true_labels, models, \"Data2txt\", tasks))\n",
    "print(compute_metrics_model(after_labels, true_labels, models, \"Data2txt\", tasks))\n",
    "print(\"Summary\")\n",
    "print(compute_metrics_model(before_labels, true_labels, models, \"Summary\", tasks))\n",
    "print(compute_metrics_model(after_labels, true_labels, models, \"Summary\", tasks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4192fcc",
   "metadata": {},
   "source": [
    "### Number of Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hallucinated token ratio analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "after_suc_hal = id_111 + id_011  # hallucinated cases that after_method success to detect\n",
    "after_fai_hal = id_001 + id_101\n",
    "before_suc_hal = id_111 + id_101\n",
    "before_fai_hal = id_001 + id_011\n",
    "\n",
    "\n",
    "after_suc_len = []\n",
    "after_fai_len = []\n",
    "before_suc_len = []\n",
    "before_fai_len = []\n",
    "for i in after_suc_hal:\n",
    "    d = test_data_span[i]\n",
    "    after_suc_len.append(d[\"hal_token\"] / d[\"all_token\"])\n",
    "for i in after_fai_hal:\n",
    "    d = test_data_span[i]\n",
    "    after_fai_len.append(d[\"hal_token\"] / d[\"all_token\"])\n",
    "for i in before_suc_hal:\n",
    "    d = test_data_span[i]\n",
    "    before_suc_len.append(d[\"hal_token\"] / d[\"all_token\"])\n",
    "for i in before_fai_hal:\n",
    "    d = test_data_span[i]\n",
    "    before_fai_len.append(d[\"hal_token\"] / d[\"all_token\"])\n",
    "\n",
    "# x-axis : hallucination token ratio\n",
    "bins = np.linspace(0, 1, 6)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "after_suc_hist, _ = np.histogram(after_suc_len, bins=bins)\n",
    "after_fai_hist, _ = np.histogram(after_fai_len, bins=bins)\n",
    "before_suc_hist, _ = np.histogram(before_suc_len, bins=bins)\n",
    "before_fai_hist, _ = np.histogram(before_fai_len, bins=bins)\n",
    "\n",
    "# calculate success ratio\n",
    "total = after_suc_hist + after_fai_hist  # total number of hallucinated cases\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    after_ratio = np.divide(after_suc_hist, total, out=np.zeros_like(after_suc_hist, dtype=float), where=total != 0)\n",
    "    before_ratio = np.divide(before_suc_hist, total, out=np.zeros_like(before_suc_hist, dtype=float), where=total != 0)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# left axis: success ratio\n",
    "ax1.plot(bin_centers, after_ratio, label=\"triplet (success rate)\")\n",
    "ax1.plot(bin_centers, before_ratio, label=\"gpt4o (success rate)\")\n",
    "ax1.set_xlabel(\"hallucination token ratio\")\n",
    "ax1.set_ylabel(\"success ratio\", color=\"black\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# right axis: case count\n",
    "ax2 = ax1.twinx()\n",
    "bar_width = (bins[1] - bins[0]) * 0.7\n",
    "ax2.bar(bin_centers, total, width=bar_width, alpha=0.3, label=\"case count\")\n",
    "ax2.set_ylabel(\"case count\", color=\"black\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.05), ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b1e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hallucinations in each case\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "after_suc_hal = id_111 + id_011\n",
    "after_fai_hal = id_001 + id_101\n",
    "before_suc_hal = id_111 + id_101\n",
    "before_fai_hal = id_001 + id_011\n",
    "\n",
    "\n",
    "after_suc_len = []\n",
    "after_fai_len = []\n",
    "before_suc_len = []\n",
    "before_fai_len = []\n",
    "for i in after_suc_hal:\n",
    "    d = test_data_span[i]\n",
    "    after_suc_len.append(len(d[\"hallucination_id\"]))\n",
    "for i in after_fai_hal:\n",
    "    d = test_data_span[i]\n",
    "    after_fai_len.append(len(d[\"hallucination_id\"]))\n",
    "for i in before_suc_hal:\n",
    "    d = test_data_span[i]\n",
    "    before_suc_len.append(len(d[\"hallucination_id\"]))\n",
    "for i in before_fai_hal:\n",
    "    d = test_data_span[i]\n",
    "    before_fai_len.append(len(d[\"hallucination_id\"]))\n",
    "\n",
    "# x-axis : number of hallucinations\n",
    "bins = np.linspace(0.5, 8.5, 9)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "after_suc_hist, _ = np.histogram(after_suc_len, bins=bins)\n",
    "after_fai_hist, _ = np.histogram(after_fai_len, bins=bins)\n",
    "before_suc_hist, _ = np.histogram(before_suc_len, bins=bins)\n",
    "before_fai_hist, _ = np.histogram(before_fai_len, bins=bins)\n",
    "\n",
    "# calculate success ratio\n",
    "total = after_suc_hist + after_fai_hist\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    after_ratio = np.divide(after_suc_hist, total, out=np.zeros_like(after_suc_hist, dtype=float), where=total != 0)\n",
    "    before_ratio = np.divide(before_suc_hist, total, out=np.zeros_like(before_suc_hist, dtype=float), where=total != 0)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# left axis: success ratio\n",
    "ax1.plot(bin_centers, after_ratio, label=\"triplet (success rate)\")\n",
    "ax1.plot(bin_centers, before_ratio, label=\"gpt4o (success rate)\")\n",
    "ax1.set_xlabel(\"hallucination num\")\n",
    "ax1.set_ylabel(\"success ratio\", color=\"black\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# right axis: case count\n",
    "ax2 = ax1.twinx()\n",
    "bar_width = (bins[1] - bins[0]) * 0.8\n",
    "ax2.bar(bin_centers, total, width=bar_width, alpha=0.3, label=\"case count\")\n",
    "ax2.set_ylabel(\"case count\", color=\"black\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "\n",
    "fig.legend(loc=\"upper center\", bbox_to_anchor=(0.5, 1.1), ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d4f635",
   "metadata": {},
   "source": [
    "### Embedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def triplet_loss(anchor_output, positive_output, negative_output, text_logits, labels):\n",
    "    text_targets = torch.tensor(labels).clone().detach().to(device)\n",
    "    classification_loss = nn.CrossEntropyLoss()(text_logits, text_targets)\n",
    "\n",
    "    triplet_loss_fn = nn.TripletMarginWithDistanceLoss(\n",
    "        margin=1.0, distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y)\n",
    "    )\n",
    "    triplet_loss = triplet_loss_fn(anchor_output, positive_output, negative_output)\n",
    "    return classification_loss, triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a76b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from train_inference_code.models.models_rob import TripletModel\n",
    "\n",
    "# to calculate similarity before training\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "\n",
    "# to calculate similarity with triplet_method\n",
    "name = \"trained_model/triplet_rob\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "base_model = AutoModel.from_pretrained(\"FacebookAI/RoBERTa-base\")\n",
    "model = TripletModel.from_pretrained(base_model, triplet_loss, name)\n",
    "\n",
    "##### \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def calc_sim(ref, text, label):\n",
    "    ref_tok = tokenizer(ref, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n",
    "    text_tok = tokenizer(text, padding=\"longest\", truncation=True, return_tensors=\"pt\")\n",
    "    sample_tok = tokenizer(\"sample\", padding=\"longest\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    if label[0] == 1:\n",
    "        # ref, sample, hallucinated text\n",
    "        inputs = {\n",
    "            \"input_ids\": [\n",
    "                ref_tok[\"input_ids\"].to(device),\n",
    "                sample_tok[\"input_ids\"].to(device),\n",
    "                text_tok[\"input_ids\"].to(device),\n",
    "            ],\n",
    "            \"attention_mask\": [\n",
    "                ref_tok[\"attention_mask\"].to(device),\n",
    "                sample_tok[\"attention_mask\"].to(device),\n",
    "                text_tok[\"attention_mask\"].to(device),\n",
    "            ],\n",
    "            \"labels\": label,\n",
    "        }\n",
    "    elif label[0] == 0:\n",
    "        # ref, faithful text, sample text\n",
    "        inputs = {\n",
    "            \"input_ids\": [\n",
    "                ref_tok[\"input_ids\"].to(device),\n",
    "                text_tok[\"input_ids\"].to(device),\n",
    "                sample_tok[\"input_ids\"].to(device),\n",
    "            ],\n",
    "            \"attention_mask\": [\n",
    "                ref_tok[\"attention_mask\"].to(device),\n",
    "                text_tok[\"attention_mask\"].to(device),\n",
    "                sample_tok[\"attention_mask\"].to(device),\n",
    "            ],\n",
    "            \"labels\": label,\n",
    "        }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    ref_output = output.output[0].cpu().numpy()\n",
    "    text_output = output.output[1].cpu().numpy()\n",
    "\n",
    "    return cosine_similarity(ref_output, text_output)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00392f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_sim(test_data_span[0][\"ref\"], test_data_span[0][\"text\"], [test_data_span[0][\"labels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "qa_cos = []\n",
    "d2t_cos = []\n",
    "sum_cos = []\n",
    "\n",
    "for d in tqdm(test_data_span):\n",
    "    sim = calc_sim(d[\"ref\"], d[\"text\"], [d[\"labels\"]])\n",
    "    if d[\"task_type\"] == \"QA\":\n",
    "        qa_cos.append(sim)\n",
    "        #d[\"sim_before\"] = sim\n",
    "        d[\"sim_triplet\"] = sim\n",
    "    elif d[\"task_type\"] == \"Data2txt\":\n",
    "        d2t_cos.append(sim)\n",
    "        #d[\"sim_before\"] = sim\n",
    "        d[\"sim_triplet\"] = sim\n",
    "    else:\n",
    "        sum_cos.append(sim)\n",
    "        #d[\"sim_before\"] = sim\n",
    "        d[\"sim_triplet\"] = sim\n",
    "\n",
    "print(\"QA\", np.mean(qa_cos))\n",
    "print(\"Data2txt\", np.mean(d2t_cos))\n",
    "print(\"Sum\", np.mean(sum_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "before_posi = []\n",
    "before_nega = []\n",
    "\n",
    "font_size=15\n",
    "\n",
    "id_all = id_000 + id_001 + id_010 + id_011 + id_100 + id_101 + id_110 + id_111\n",
    "id_tri_fail = id_001 + id_010 + id_101 + id_110\n",
    "id_tri_suc = id_000 + id_011 + id_100 + id_111\n",
    "for i in id_all :\n",
    "    d = test_data_span[i]\n",
    "    mode = \"sim_before\" # \"sim_triplet\" for triplet method\n",
    "    if d[\"labels\"] == 1:\n",
    "        before_nega.append(1 - d[mode]) # 1 - cosine similarity to convert to distance\n",
    "    else:\n",
    "        before_posi.append(1 - d[mode])\n",
    "\n",
    "\n",
    "mean_posi = np.mean(before_posi)\n",
    "mean_nega = np.mean(before_nega)\n",
    "\n",
    "\n",
    "plt.hist(before_posi, bins=100, alpha=0.5, label=\"Faithful\")\n",
    "plt.hist(before_nega, bins=100, alpha=0.5, label=\"Hallucinated\")\n",
    "\n",
    "\n",
    "plt.axvline(mean_posi, color='blue', linestyle='dashed', linewidth=1.8, label=f\"Mean Faithful ({mean_posi:.2f})\")\n",
    "plt.axvline(mean_nega, color='orange', linestyle='dashed', linewidth=1.8, label=f\"Mean Hallucinated ({mean_nega:.2f})\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Cosine distance\", fontsize=font_size)\n",
    "plt.ylabel(\"Count\", fontsize=font_size)\n",
    "plt.xticks(fontsize=font_size)\n",
    "plt.yticks(fontsize=font_size)\n",
    "plt.legend(fontsize=font_size)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".acl2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
